{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcdf2ec",
   "metadata": {},
   "source": [
    "# Table Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab630e3",
   "metadata": {},
   "source": [
    "### Using langchain_Pypdfloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5529254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Adobe PDF Library 19.1.77', 'creator': 'Acrobat PDFMaker 19 for Word', 'creationdate': '2018-09-11T09:33:20-04:00', 'author': 'Rob Haverty', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2018-09-11T09:33:21-04:00', 'sourcemodified': 'D:20180910225652', 'subject': '', 'title': '', 'source': 'D:\\\\Work\\\\Generative AI\\\\Advance Doc parsing\\\\data\\\\EX2c-Complex-Table.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Complex Table – More Techniques for PDF Accessibility \\nMerged Header \\nColumn/Row \\nMerged Header Column 1 \\nH1 H2 H3 H4 H5 H6 \\nMHR1 HR1 D1 D2 D3 D4 D5 D6 \\nHR2 D7 D8 D9 D10 D11 D12 \\nMHR2 HR3 D13 D14 D15 D16 D17 D18 \\nHR4 D19 D20 D21 D22 D23 D24 \\n \\nMerged Header Column/Row 1 \\nMerged Header Column 1 \\nHC1 HC2 HC3 HC4 HC5 HC6 HC7 HC8 HC9 HC10 HC11 HC12 \\nMHC 2 MHC 3 MHC 4 MHC 5 \\nMerged Header \\nRow 1 \\nHR1 D1 D2 D3 D4 D5 D6 D7 D8 D9 D10 D11 D12 \\nHR2 D13 D14 D15 D16 D17 D18 D19 D20 D21 D22 D23 D24 \\nMerged Header \\nRow 2 \\nHR3 D25 D26 D27 D28 D29 D30 D31 D32 D33 D34 D35 D36 \\nHR4 D37 D38 D39 D40 D41 D42 D43 D44 D45 D46 D47 D48')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Step 1: Define PDF path and output directory\n",
    "pdf_path = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\EX2c-Complex-Table.pdf\"  # Replace with your PDF path\n",
    "output_dir = \"Output_Table_Text\"\n",
    "output_file = os.path.join(output_dir, \"Langchain_pypdfloader.txt\")\n",
    "\n",
    "# Step 2: Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 3: Load PDF using PyPDFLoader\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "print(pages)\n",
    "\n",
    "# # Step 4: Extract text and combine\n",
    "# all_text = \"\\n\\n\".join([page.page_content for page in pages])\n",
    "\n",
    "# # Step 5: Save to output file\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(all_text)\n",
    "\n",
    "# print(f\"✅ Text saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf3b66",
   "metadata": {},
   "source": [
    "### Unststructured (see unstructured Folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31754f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eea86711",
   "metadata": {},
   "source": [
    "### Docling Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text saved to: Output_Table_Text\\docling.txt\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\EX2c-Complex-Table.pdf\"  # document per local path or URL\n",
    "output_dir = \"Output_Table_Text\"\n",
    "output_file = os.path.join(output_dir, \"docling.txt\")\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "resultss=result.document.export_to_markdown() # output: \"## Docling Technical Report[...]\"\n",
    "\n",
    "\n",
    "# Step 5: Save to output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(resultss)\n",
    "\n",
    "print(f\"✅ Text saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28982d88",
   "metadata": {},
   "source": [
    "#### Docling Performs Exceptionlly well on Complex table Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e1909",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bdde5f0",
   "metadata": {},
   "source": [
    "##  Table Extraction Example 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "327a6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_single_page(pdf_path, page_number, output_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    single_page = fitz.open()  # new PDF\n",
    "    single_page.insert_pdf(doc, from_page=page_number-1, to_page=page_number-1)\n",
    "    single_page.save(output_path)\n",
    "    single_page.close()\n",
    "    doc.close()\n",
    "\n",
    "# Step 1: Extract page 25\n",
    "extract_single_page(r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\Auto Chunker.pdf\", 6, r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\AutoChunker_Tabke.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "source = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\AutoChunker_Tabke.pdf\"  # document per local path or URL\n",
    "output_dir = \"Output_Table_Text\"\n",
    "output_file = os.path.join(output_dir, \"docling.txt\")\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "resultss=result.document.export_to_markdown() # output: \"## Docling Technical Report[...]\"\n",
    "\n",
    "\n",
    "# Step 5: Save to output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(resultss)\n",
    "\n",
    "print(f\"✅ Text saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcb074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ed5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77cae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b627b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93e71d43",
   "metadata": {},
   "source": [
    "# Comparing Formula Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135192b6",
   "metadata": {},
   "source": [
    "### Using Langchains Pypdfloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447a018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text saved to: Output/pypdf_output.txt\\extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Step 1: Define PDF path and output directory\n",
    "pdf_path = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\formula.pdf\"  # Replace with your PDF path\n",
    "output_dir = \"Output\n",
    "output_file = os.path.join(output_dir, \"Langchain_pypdfloader.txt\")\n",
    "\n",
    "# Step 2: Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 3: Load PDF using PyPDFLoader\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()\n",
    "\n",
    "# Step 4: Extract text and combine\n",
    "all_text = \"\\n\\n\".join([page.page_content for page in pages])\n",
    "\n",
    "# Step 5: Save to output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)\n",
    "\n",
    "print(f\"✅ Text saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57490ef1",
   "metadata": {},
   "source": [
    "### Using PyMupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb77a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text extracted and saved to: Output\\PyMuPDF.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Define paths\n",
    "input_pdf_path = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\formula.pdf\"\n",
    "output_dir = \"Output\"\n",
    "output_file = os.path.join(output_dir, \"PyMuPDF.txt\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the PDF and extract all text\n",
    "doc = fitz.open(input_pdf_path)\n",
    "all_text = \"\"\n",
    "for page in doc:\n",
    "    all_text += page.get_text() + \"\\n\\n\"\n",
    "doc.close()\n",
    "\n",
    "# Save the extracted text\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)\n",
    "\n",
    "print(f\"✅ Text extracted and saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68964d8c",
   "metadata": {},
   "source": [
    "### Using Docling Formula Enrichment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52858779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     19\u001b[39m converter = DocumentConverter(format_options={\n\u001b[32m     20\u001b[39m     InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n\u001b[32m     21\u001b[39m })\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Step 5: Convert PDF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m result = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m doc = result.document\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Step 6: Export to Markdown\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\document_converter.py:235\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    226\u001b[39m ) -> ConversionResult:\n\u001b[32m    227\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    228\u001b[39m         source=[source],\n\u001b[32m    229\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m         page_range=page_range,\n\u001b[32m    234\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\document_converter.py:258\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    255\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    257\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\document_converter.py:293\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    284\u001b[39m _log.info(\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\document_converter.py:339\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    335\u001b[39m valid = (\n\u001b[32m    336\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    337\u001b[39m )\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    341\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\document_converter.py:362\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    360\u001b[39m pipeline = \u001b[38;5;28mself\u001b[39m._get_pipeline(in_doc.format)\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     conv_res = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:49\u001b[39m, in \u001b[36mBasePipeline.execute\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m     47\u001b[39m         conv_res = \u001b[38;5;28mself\u001b[39m._assemble_document(conv_res)\n\u001b[32m     48\u001b[39m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_enrich_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m         conv_res.status = \u001b[38;5;28mself\u001b[39m._determine_status(conv_res)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:84\u001b[39m, in \u001b[36mBasePipeline._enrich_document\u001b[39m\u001b[34m(self, conv_res)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enrichment_pipe:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m element_batch \u001b[38;5;129;01min\u001b[39;00m chunkify(\n\u001b[32m     81\u001b[39m             _prepare_elements(conv_res, model),\n\u001b[32m     82\u001b[39m             model.elements_batch_size,\n\u001b[32m     83\u001b[39m         ):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43melement_batch\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Must exhaust!\u001b[39;49;00m\n\u001b[32m     87\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conv_res\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling\\models\\code_formula_model.py:318\u001b[39m, in \u001b[36mCodeFormulaModel.__call__\u001b[39m\u001b[34m(self, doc, element_batch)\u001b[39m\n\u001b[32m    313\u001b[39m     labels.append(el.item.label)\n\u001b[32m    314\u001b[39m     images.append(\n\u001b[32m    315\u001b[39m         \u001b[38;5;28mself\u001b[39m._pad_with_most_frequent_edge_color(el.image, (\u001b[32m20\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m    316\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcode_formula_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(elements, outputs):\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, CodeItem):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\docling_ibm_models\\code_formula_model\\code_formula_predictor.py:261\u001b[39m, in \u001b[36mCodeFormulaPredictor.predict\u001b[39m\u001b[34m(self, images, labels, temperature)\u001b[39m\n\u001b[32m    250\u001b[39m stopping_criteria = StoppingCriteriaList(\n\u001b[32m    251\u001b[39m     [\n\u001b[32m    252\u001b[39m         StopOnString(\u001b[38;5;28mself\u001b[39m._tokenizer, \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mquad \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mquad \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mquad \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mquad\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m     ]\n\u001b[32m    258\u001b[39m )\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._device == \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m     output_ids_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(device_type=\u001b[38;5;28mself\u001b[39m._device, dtype=torch.bfloat16):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2625\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2617\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2618\u001b[39m         input_ids=input_ids,\n\u001b[32m   2619\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2620\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2621\u001b[39m         **model_kwargs,\n\u001b[32m   2622\u001b[39m     )\n\u001b[32m   2624\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2625\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2632\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2633\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2636\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2637\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2638\u001b[39m         input_ids=input_ids,\n\u001b[32m   2639\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2640\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2641\u001b[39m         **model_kwargs,\n\u001b[32m   2642\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3625\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3622\u001b[39m next_token_logits = outputs.logits[:, -\u001b[32m1\u001b[39m, :].to(copy=\u001b[38;5;28;01mTrue\u001b[39;00m, dtype=torch.float32, device=input_ids.device)\n\u001b[32m   3624\u001b[39m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3625\u001b[39m next_token_scores = \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3627\u001b[39m \u001b[38;5;66;03m# Store scores, attentions and hidden_states when required\u001b[39;00m\n\u001b[32m   3628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\transformers\\generation\\logits_process.py:93\u001b[39m, in \u001b[36mLogitsProcessorList.__call__\u001b[39m\u001b[34m(self, input_ids, scores, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         scores = processor(input_ids, scores, **kwargs)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m         scores = \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Work\\Generative AI\\Advance Doc parsing\\.venv\\Lib\\site-packages\\transformers\\generation\\logits_process.py:987\u001b[39m, in \u001b[36mNoRepeatNGramLogitsProcessor.__call__\u001b[39m\u001b[34m(self, input_ids, scores)\u001b[39m\n\u001b[32m    985\u001b[39m banned_batch_tokens = _calc_banned_ngram_tokens(\u001b[38;5;28mself\u001b[39m.ngram_size, input_ids, num_batch_hypotheses, cur_len)\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, banned_tokens \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(banned_batch_tokens):\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     scores_processed[i, banned_tokens] = -\u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m scores_processed\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "# Step 1: Define PDF and output paths\n",
    "pdf_path = r\"D:\\Work\\Generative AI\\Advance Doc parsing\\data\\formula.pdf\"\n",
    "output_dir = \"Output\"\n",
    "output_file = os.path.join(output_dir, \"docling.md\")\n",
    "\n",
    "# Step 2: Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 3: Setup pipeline with formula enrichment\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_formula_enrichment = True\n",
    "\n",
    "# Step 4: Create converter with options\n",
    "converter = DocumentConverter(format_options={\n",
    "    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "})\n",
    "\n",
    "# Step 5: Convert PDF\n",
    "result = converter.convert(pdf_path)\n",
    "doc = result.document\n",
    "\n",
    "# Step 6: Export to Markdown\n",
    "markdown_content = doc.export_to_markdown()\n",
    "\n",
    "# Step 7: Save markdown content to .md file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "print(f\"✅ Markdown saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b95f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Advance Doc parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
